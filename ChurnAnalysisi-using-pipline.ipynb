{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9urYKdWhxgb/JtvkmwLVE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3F7eObGZXWzW"},"outputs":[],"source":[]},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ug_OHLbRXXtR","executionInfo":{"status":"ok","timestamp":1746701236492,"user_tz":-180,"elapsed":17160,"user":{"displayName":"Maliha Farahmand","userId":"04602418993537699166"}},"outputId":"a16060e1-adcb-4d7d-bf2f-2b5609e0ce36"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, roc_auc_score\n","import xgboost as xgb\n","import joblib\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from collections import defaultdict\n","import xgboost as xgb\n","from lightgbm import LGBMClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# 1. Veriyi yükle\n","df = pd.read_csv('/content/drive/MyDrive/churn_train.csv')\n","df = df.drop(['user_account_id'], axis=1)\n","\n","# 2. Özelleştirilmiş ön işleyiciler\n","class AutoOutlierFlagger(BaseEstimator, TransformerMixin):\n","    def __init__(self, threshold=10.0):\n","        self.threshold = threshold\n","        self.columns_to_flag = []\n","        self.bounds = {}\n","\n","    def fit(self, X, y=None):\n","        numeric_cols = X.select_dtypes(include=[np.number]).columns\n","        for col in numeric_cols:\n","            Q1 = X[col].quantile(0.25)\n","            Q3 = X[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower = Q1 - 1.5 * IQR\n","            upper = Q3 + 1.5 * IQR\n","            outliers = ((X[col] < lower) | (X[col] > upper)).sum()\n","            percentage = (outliers / len(X)) * 100\n","            if percentage > self.threshold:\n","                self.columns_to_flag.append(col)\n","                self.bounds[col] = (lower, upper)\n","        return self\n","\n","    def transform(self, X):\n","        X_ = X.copy()\n","        for col in self.columns_to_flag:\n","            lower, upper = self.bounds[col]\n","            X_[f\"{col}_outlier\"] = ((X_[col] < lower) | (X_[col] > upper)).astype(int)\n","        return X_\n","\n","class DropLowVariance(BaseEstimator, TransformerMixin):\n","    def __init__(self, threshold=0.01):\n","        self.threshold = threshold\n","        self.columns_to_drop = []\n","\n","    def fit(self, X, y=None):\n","        variances = X.var()\n","        self.columns_to_drop = variances[variances < self.threshold].index.tolist()\n","        return self\n","\n","    def transform(self, X):\n","        return X.drop(columns=self.columns_to_drop, errors='ignore')\n","\n","class DropHighlyCorrelated(BaseEstimator, TransformerMixin):\n","    def __init__(self, threshold=0.9):\n","        self.threshold = threshold\n","        self.cols_to_drop = []\n","\n","    def fit(self, X, y=None):\n","        corr_matrix = X.corr().abs()\n","        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","        self.cols_to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n","        return self\n","\n","    def transform(self, X):\n","        return X.drop(columns=self.cols_to_drop, errors='ignore')\n","\n","# 3. Hedef değişken ve özellikleri ayır\n","\n","\n","# Modelleri tanımlayalım\n","models = {\n","    \"RandomForest\": RandomForestClassifier(random_state=42),\n","    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n","    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n","    \"XGBoost\": xgb.XGBClassifier( eval_metric='logloss', random_state=42),\n","    \"LightGBM\": LGBMClassifier(random_state=42)\n","}\n","\n","# Veri hazırlığı\n","X = df.drop(columns='churn')\n","y = df['churn']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Sonuçları saklayacak bir sözlük\n","results = defaultdict(list)\n","\n","# Model Pipeline içinde kullanılacak veri ön işleme adımları\n","def create_pipeline(model):\n","    return Pipeline(steps=[\n","        ('outlier_flags', AutoOutlierFlagger(threshold=10.0)),  # %10'dan fazla aykırı varsa flagle\n","        ('low_variance_filter', DropLowVariance()),  # Varyansı düşük olanları çıkar\n","        ('correlation_filter', DropHighlyCorrelated()),  # Korelasyonu yüksek olanları çıkar\n","        ('scaling', StandardScaler()),  # Veriyi standardlaştır\n","        ('classifier', model)  # Modeli ekle\n","    ])\n","\n","# Modelleri sırasıyla eğitelim ve test edelim\n","for model_name, model in models.items():\n","    print(f\"Training {model_name}...\")\n","\n","    # Pipeline kurulumu\n","    pipeline = create_pipeline(model)\n","\n","    # Modeli eğit\n","    pipeline.fit(X_train, y_train)\n","\n","    # Tahmin yap\n","    y_pred = pipeline.predict(X_test)\n","    y_proba = pipeline.predict_proba(X_test)[:, 1]  # ROC AUC için\n","\n","    # Performans değerlendirme\n","    results[model_name].append(accuracy_score(y_test, y_pred))  # Accuracy\n","    results[model_name].append(roc_auc_score(y_test, y_proba))  # ROC AUC\n","    results[model_name].append(classification_report(y_test, y_pred))  # Detaylı rapor\n","\n","    # Eğitilen modeli kaydedelim\n","    joblib.dump(pipeline, f\"{model_name}_model.joblib\")  # Modeli kaydet\n","\n","# Sonuçları yazdıralım\n","for model_name in results:\n","    print(f\"\\n{model_name} Model Results:\")\n","    print(f\"Accuracy: {results[model_name][0]:.4f}\")\n","    print(f\"ROC AUC Score: {results[model_name][1]:.4f}\")\n","    print(f\"Classification Report:\\n{results[model_name][2]}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFsz2uNUXXuP","executionInfo":{"status":"ok","timestamp":1746701357441,"user_tz":-180,"elapsed":60288,"user":{"displayName":"Maliha Farahmand","userId":"04602418993537699166"}},"outputId":"1afcdd07-0bab-4be2-e2fa-9d91c7c55fe2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training RandomForest...\n","Training GradientBoosting...\n","Training AdaBoost...\n","Training XGBoost...\n","Training LightGBM...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Number of positive: 8784, number of negative: 33216\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025888 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 8340\n","[LightGBM] [Info] Number of data points in the train set: 42000, number of used features: 68\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.209143 -> initscore=-1.330100\n","[LightGBM] [Info] Start training from score -1.330100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","RandomForest Model Results:\n","Accuracy: 0.8704\n","ROC AUC Score: 0.8953\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.94      0.92     14235\n","           1       0.72      0.62      0.67      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.81      0.78      0.79     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n","\n","GradientBoosting Model Results:\n","Accuracy: 0.8734\n","ROC AUC Score: 0.9040\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.92      0.92     14235\n","           1       0.70      0.68      0.69      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.81      0.80      0.81     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n","\n","AdaBoost Model Results:\n","Accuracy: 0.8653\n","ROC AUC Score: 0.8968\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.91      0.91     14235\n","           1       0.68      0.68      0.68      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.80      0.80      0.80     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n","\n","XGBoost Model Results:\n","Accuracy: 0.8723\n","ROC AUC Score: 0.8994\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      0.93      0.92     14235\n","           1       0.71      0.67      0.69      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.81      0.80      0.80     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n","\n","LightGBM Model Results:\n","Accuracy: 0.8741\n","ROC AUC Score: 0.9044\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.92      0.92     14235\n","           1       0.71      0.68      0.69      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.81      0.80      0.81     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n"]}]},{"cell_type":"code","source":["# Modeli yükleyelim\n","loaded_model = joblib.load(\"RandomForest_model.joblib\")  # Örneğin RandomForest modelini yükledik\n","\n","# Yüklenen model ile tahmin yapalım\n","y_pred_loaded = loaded_model.predict(X_test)\n","y_proba_loaded = loaded_model.predict_proba(X_test)[:, 1]\n","\n","# Performans değerlendirme\n","print(\"Loaded Model - Accuracy: \", accuracy_score(y_test, y_pred_loaded))\n","print(\"Loaded Model - ROC AUC Score: \", roc_auc_score(y_test, y_proba_loaded))\n","print(\"Loaded Model - Classification Report:\\n\", classification_report(y_test, y_pred_loaded))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YY0bUlvhdfi","executionInfo":{"status":"ok","timestamp":1746701514197,"user_tz":-180,"elapsed":1413,"user":{"displayName":"Maliha Farahmand","userId":"04602418993537699166"}},"outputId":"5b4a6521-429e-43ee-d88b-63078b560e95"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Model - Accuracy:  0.8704444444444445\n","Loaded Model - ROC AUC Score:  0.8953059230120847\n","Loaded Model - Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.94      0.92     14235\n","           1       0.72      0.62      0.67      3765\n","\n","    accuracy                           0.87     18000\n","   macro avg       0.81      0.78      0.79     18000\n","weighted avg       0.87      0.87      0.87     18000\n","\n"]}]}]}